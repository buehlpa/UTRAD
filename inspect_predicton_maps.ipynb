{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from models import Create_nets\n",
    "from datasets import Get_dataloader\n",
    "#from options import TrainOptions\n",
    "from torchvision import models\n",
    "import os\n",
    "from PIL import Image\n",
    "import torchvision.transforms.functional as TF\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#args = TrainOptions().parse() # surpass kernelerror with this:\n",
    "\n",
    "class TrainOptions:\n",
    "    def __init__(self):\n",
    "        self.exp_name = \"Exp0-r18\"\n",
    "        self.epoch_start = 0\n",
    "        self.epoch_num = 150\n",
    "        self.factor = 1\n",
    "        self.seed = 233\n",
    "        self.num_row = 4\n",
    "        self.activation = 'gelu'\n",
    "        self.unalign_test = False\n",
    "        self.data_root = '/home/bule/projects/datasets/mvtec_anomaly_detection/'\n",
    "        self.dataset_name = \"cable\"\n",
    "        self.batch_size = 2\n",
    "        self.lr = 1e-4\n",
    "        self.b1 = 0.5\n",
    "        self.b2 = 0.999\n",
    "        self.n_cpu = 8\n",
    "        self.image_result_dir = 'result_images'\n",
    "        self.model_result_dir = 'saved_models'\n",
    "        self.validation_image_dir = 'validation_images'\n",
    "\n",
    "# Example of how to use this class\n",
    "args = TrainOptions()\n",
    "\n",
    "torch.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_categories = {\n",
    "    'bottle': ['broken_large', 'broken_small', 'contamination'],\n",
    "    'cable': ['bent_wire', 'cable_swap', 'combined', 'cut_inner_insulation', 'cut_outer_insulation', 'missing_cable', 'missing_wire', 'poke_insulation'],\n",
    "    'capsule': ['crack', 'faulty_imprint', 'poke', 'scratch','squeeze'],\n",
    "    'carpet': ['color', 'cut', 'hole', 'metal_contamination', 'thread'],\n",
    "    'grid': ['bent', 'broken', 'glue', 'metal_contamination', 'thread'],\n",
    "    'hazelnut': ['crack', 'cut', 'hole', 'print'],\n",
    "    'leather': ['color', 'cut', 'fold', 'glue', 'poke'],\n",
    "    'metal_nut': ['bent', 'color', 'flip', 'scratch'],\n",
    "    'pill': ['color', 'combined','contamination', 'crack', 'faulty_imprint', 'pill_type','scratch'],\n",
    "    'screw': ['manipulated_front', 'scratch_head', 'scratch_neck','thread_side', 'thread_top'],\n",
    "    'tile': ['crack', 'glue_strip', 'gray_stroke', 'oil','rough'],\n",
    "    'toothbrush': ['defective'],\n",
    "    'transistor': ['bent_lead', 'cut_lead', 'damaged_case', 'misplaced'],\n",
    "    'wood': ['color', 'combined', 'hole', 'liquid', 'scratch'],\n",
    "    'zipper': ['broken_teeth', 'combined','fabric_border', 'fabric_interior','split_teeth','rough', 'squeezed_teeth']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "category= \"screw\"\n",
    "anomaly_category=\"manipulated_front\"\n",
    "\n",
    "\n",
    "# define some images for inspecting good train , good test and anomaly test\n",
    "good_img_train_path = os.path.join(args.data_root,f'{category}/train/good/003.png') \n",
    "good_img_test_path = os.path.join(args.data_root,f'{category}/test/good/003.png')\n",
    "anomaly_img_test_path = os.path.join(args.data_root,f'{category}/test/{anomaly_category}/004.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## laod a saved model to inspect \n",
    "\n",
    "\n",
    "\n",
    "SAVE_PATH='./inspects'\n",
    "\n",
    "## Load Pretrained  Trafo model\n",
    "transformer = Create_nets(args).to(device)\n",
    "checkpoint = torch.load(f'./Exp0-r18-{category}/saved_models/checkpoint.pth')\n",
    "transformer.load_state_dict(checkpoint['transformer'])\n",
    "#print(transformer)\n",
    "\n",
    "# Backbone hooks\n",
    "backbone = models.resnet18(pretrained=True).to(device)\n",
    "backbone.eval()\n",
    "outputs = []\n",
    "def hook(module, input, output):\n",
    "    outputs.append(output)\n",
    "backbone.layer1[-1].register_forward_hook(hook)\n",
    "backbone.layer2[-1].register_forward_hook(hook)\n",
    "backbone.layer3[-1].register_forward_hook(hook)\n",
    "\n",
    "def embedding_concat(x, y):\n",
    "    B, C1, H1, W1 = x.size()\n",
    "    _, C2, H2, W2 = y.size()\n",
    "    s = int(H1 / H2)\n",
    "    x = F.unfold(x, kernel_size=s, dilation=1, stride=s)\n",
    "    x = x.view(B, C1, -1, H2, W2)\n",
    "    z = torch.zeros(B, C1 + C2, x.size(2), H2, W2).to(device)\n",
    "    for i in range(x.size(2)):\n",
    "        z[:, :, i, :, :] = torch.cat((x[:, :, i, :, :], y), 1)\n",
    "    z = z.view(B, -1, H2 * W2)\n",
    "    z = F.fold(z, kernel_size=s, output_size=(H1, W1), stride=s)\n",
    "    return z\n",
    "\n",
    "def load_image(filename,crop_size=256,aligned=True, img_size=280):\n",
    "        img = Image.open(filename)\n",
    "        img = img.convert('RGB')\n",
    "        \n",
    "        if aligned:\n",
    "            img = TF.resize(img, crop_size, Image.BICUBIC)\n",
    "            img = TF.to_tensor(img)\n",
    "            img = TF.normalize(img, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225 ])\n",
    "        else:\n",
    "            img = TF.resize(img, img_size, Image.BICUBIC)\n",
    "            angle = transforms.RandomRotation.get_params([-10, 10])\n",
    "            img = TF.rotate(img, angle, fill=(0,))\n",
    "            i, j, h, w = transforms.RandomCrop.get_params(img, output_size=(crop_size, crop_size))\n",
    "            img = TF.crop(img, i, j, h, w)\n",
    "            img = TF.to_tensor(img)\n",
    "            img = TF.normalize(img, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225 ])    \n",
    "            img=img.to(torch.float32)\n",
    "        return img\n",
    "    \n",
    "def plot_images(images):\n",
    "    num_images = images.shape[0]\n",
    "    num_rows = int(num_images ** 0.5)\n",
    "    num_cols = num_images // num_rows\n",
    "    fig, axes = plt.subplots(nrows=num_rows, ncols=num_cols, figsize=(20, 20))\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        ax.imshow(images[i], cmap='viridis')\n",
    "        ax.axis('off')\n",
    "    plt.subplots_adjust(wspace=0.01, hspace=0.05)  # Adjust the spacing between subplots\n",
    "    plt.show()\n",
    "    \n",
    "def plot_multi_map(resdict,title,index):\n",
    "    squared_difftotal=(resdict['featuremaps'][index][:,:,:,:].squeeze().cpu().numpy()-resdict['recons'][index][:,:,:,:].squeeze().cpu().numpy())**2\n",
    "    squared_diffhigh=(resdict['featuremaps'][index][:,:64,:,:].squeeze().cpu().numpy()-resdict['recons'][index][:,:64,:,:].squeeze().cpu().numpy())**2\n",
    "    squared_diffmid=(resdict['featuremaps'][index][:,64:128,:,:].squeeze().cpu().numpy()-resdict['recons'][index][:,64:128,:,:].squeeze().cpu().numpy())**2\n",
    "    squared_difflow=(resdict['featuremaps'][index][:,128:,:,:].squeeze().cpu().numpy()-resdict['recons'][index][:,128:,:,:].squeeze().cpu().numpy())**2\n",
    "\n",
    "    squared_diffs = [squared_difftotal, squared_diffhigh, squared_diffmid, squared_difflow]\n",
    "    titles = ['Total Squared Difference', 'High Squared Difference', 'Mid Squared Difference', 'Low Squared Difference']\n",
    "    fig, axes = plt.subplots(1, len(squared_diffs) + 3, figsize=(20, 4))\n",
    "    axes[0].imshow(Image.open(resdict['paths'][index]))\n",
    "    axes[0].set_title(f'Original {title}'),axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow( sum(squared_difftotal)/resdict['stds'][index])\n",
    "    axes[1].set_title(f'Total Squared Difference/ stds'),axes[1].axis('off')\n",
    "    \n",
    "    axes[2].imshow(resdict['distances'][index])\n",
    "    axes[2].set_title(f'distances (paper)'),axes[2].axis('off')\n",
    "    \n",
    "    for i, squared_diff in enumerate(squared_diffs):\n",
    "        axes[i+3].imshow(sum(squared_diff))\n",
    "        axes[i+3].set_title(titles[i])\n",
    "        axes[i+3].axis('off')\n",
    "    plt.tight_layout(),plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " define some images for ineference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_list=[good_img_train_path,good_img_test_path,anomaly_img_test_path]\n",
    "img_list=[load_image(path,aligned=False) for path in path_list]\n",
    "\n",
    "featuremaps=[]\n",
    "recons=[]\n",
    "stds=[]\n",
    "distances=[]\n",
    "with torch.no_grad():\n",
    "    for img in img_list:\n",
    "        img=img.unsqueeze(0).to(device)\n",
    "        outputs = []\n",
    "        _ = backbone(img)  \n",
    "        outputs = embedding_concat(embedding_concat(outputs[0],outputs[1]),outputs[2])\n",
    "        recon, std = transformer(outputs)\n",
    "        featuremaps.append(outputs)\n",
    "        recons.append(recon)\n",
    "        stds.append(std.squeeze().cpu().numpy())\n",
    "        \n",
    "        dist = torch.norm(recon - outputs, p = 2, dim = 1, keepdim = True).div(std.abs())\n",
    "        \n",
    "        print(dist.shape)\n",
    "        \n",
    "        distances.append(dist.squeeze().cpu().numpy())\n",
    "\n",
    "        ### TODO implementation viszualiasation   of scores , ev with other methods can be done better..\n",
    "\n",
    "resdict={'paths':path_list,'featuremaps':featuremaps,'recons':recons,'stds':stds, 'distances':distances}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO understand predicitions as in paper \n",
    "\n",
    "# dist = torch.norm(recon - outputs, p = 2, dim = 1, keepdim = True).div(std.abs())\n",
    "\n",
    "\n",
    "\n",
    "# dist = dist.view(batch_size, 1, width, height)\n",
    "\n",
    "# patch_normed_score = []\n",
    "# for j in range(4):\n",
    "#     patch_size = pow(4, j)\n",
    "#     patch_score = F.conv2d(input=dist, \n",
    "#         weight=(torch.ones(1,1,patch_size,patch_size) / (patch_size*patch_size)).to(device), \n",
    "#         bias=None, stride=patch_size, padding=0, dilation=1)\n",
    "#     patch_score = F.avg_pool2d(dist,patch_size,patch_size)\n",
    "#     patch_score = F.interpolate(patch_score, (width,height), mode='bilinear')\n",
    "#     patch_normed_score.append(patch_score)\n",
    "    \n",
    "# score = torch.zeros(batch_size,1,64,64).to(device)\n",
    "\n",
    "\n",
    "# for j in range(4):\n",
    "#     score = embedding_concat(score, patch_normed_score[j])\n",
    "\n",
    "# score = F.conv2d(input=score, weight=torch.tensor([[[[0.0]],[[0.25]],[[0.25]],[[0.25]],[[0.25]]]]).to(device), bias=None, stride=1, padding=0, dilation=1)\n",
    "\n",
    "# score = F.interpolate(score, (ground_truth.size(2),ground_truth.size(3)), mode='bilinear')\n",
    "\n",
    "# heatmap = score.repeat(1,3,1,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(10, 4))\n",
    "axes[0].imshow(Image.open(resdict['paths'][0]))\n",
    "axes[0].set_title('Good Train Image')\n",
    "axes[0].axis('off')\n",
    "axes[1].imshow(Image.open(resdict['paths'][1]))\n",
    "axes[1].set_title('Good Test Image')\n",
    "axes[1].axis('off')\n",
    "axes[2].imshow(Image.open(resdict['paths'][2]))\n",
    "axes[2].set_title('Anomaly Test Image')\n",
    "axes[2].axis('off')\n",
    "plt.tight_layout(),plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_multi_map(resdict,title=\"train good\",index=0)\n",
    "plot_multi_map(resdict,title=\"test good\",index=1)\n",
    "plot_multi_map(resdict,title=f\"test anomaly {anomaly_category}\",index=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squared_difftotal=(resdict['featuremaps'][0][:,:,:,:].squeeze().cpu().numpy()-resdict['recons'][0][:,:,:,:].squeeze().cpu().numpy())**2\n",
    "squared_diffhigh=(resdict['featuremaps'][0][:,:64,:,:].squeeze().cpu().numpy()-resdict['recons'][0][:,:64,:,:].squeeze().cpu().numpy())**2\n",
    "squared_diffmid=(resdict['featuremaps'][0][:,64:128,:,:].squeeze().cpu().numpy()-resdict['recons'][0][:,64:128,:,:].squeeze().cpu().numpy())**2\n",
    "squared_difflow=(resdict['featuremaps'][0][:,128:,:,:].squeeze().cpu().numpy()-resdict['recons'][0][:,128:,:,:].squeeze().cpu().numpy())**2\n",
    "\n",
    "squared_diffs = [squared_difftotal, squared_diffhigh, squared_diffmid, squared_difflow]\n",
    "titles = ['Total Squared Difference', 'High Squared Difference', 'Mid Squared Difference', 'Low Squared Difference']\n",
    "fig, axes = plt.subplots(1, len(squared_diffs) + 1, figsize=(20, 4))\n",
    "axes[0].imshow(Image.open(resdict['paths'][0]))\n",
    "axes[0].set_title('Original')\n",
    "axes[0].axis('off')\n",
    "for i, squared_diff in enumerate(squared_diffs):\n",
    "    axes[i+1].imshow(sum(squared_diff))\n",
    "    axes[i+1].set_title(titles[i])\n",
    "    axes[i+1].axis('off')\n",
    "plt.tight_layout(),plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plot_images(resdict['featuremaps'][0][:,:64:,:,:].squeeze().cpu().numpy())\n",
    "plot_images(resdict['recons'][0][:,:64,:,:].squeeze().cpu().numpy())\n",
    "plot_images((resdict['featuremaps'][0][:,:64,:,:].squeeze().cpu().numpy()-resdict['recons'][0][:,:64,:,:].squeeze().cpu().numpy())**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squared_difftotal=(resdict['featuremaps'][1][:,:,:,:].squeeze().cpu().numpy()-resdict['recons'][1][:,:,:,:].squeeze().cpu().numpy())**2\n",
    "squared_diffhigh=(resdict['featuremaps'][1][:,:64,:,:].squeeze().cpu().numpy()-resdict['recons'][1][:,:64,:,:].squeeze().cpu().numpy())**2\n",
    "squared_diffmid=(resdict['featuremaps'][1][:,64:128,:,:].squeeze().cpu().numpy()-resdict['recons'][1][:,64:128,:,:].squeeze().cpu().numpy())**2\n",
    "squared_difflow=(resdict['featuremaps'][1][:,128:,:,:].squeeze().cpu().numpy()-resdict['recons'][1][:,128:,:,:].squeeze().cpu().numpy())**2\n",
    "\n",
    "squared_diffs = [squared_difftotal, squared_diffhigh, squared_diffmid, squared_difflow]\n",
    "titles = ['Total Squared Difference', 'High Squared Difference', 'Mid Squared Difference', 'Low Squared Difference']\n",
    "fig, axes = plt.subplots(1, len(squared_diffs) + 1, figsize=(20, 4))\n",
    "axes[0].imshow(Image.open(resdict['paths'][1]))\n",
    "axes[0].set_title('Original')\n",
    "axes[0].axis('off')\n",
    "for i, squared_diff in enumerate(squared_diffs):\n",
    "    axes[i+1].imshow(sum(squared_diff))\n",
    "    axes[i+1].set_title(titles[i])\n",
    "    axes[i+1].axis('off')\n",
    "plt.tight_layout(),plt.show()\n",
    "\n",
    "\n",
    "plot_images(resdict['featuremaps'][1][:,:64,:,:].squeeze().cpu().numpy())\n",
    "plot_images(resdict['recons'][1][:,:64,:,:].squeeze().cpu().numpy())\n",
    "plot_images((resdict['featuremaps'][1][:,:64,:,:].squeeze().cpu().numpy()-resdict['recons'][1][:,:64,:,:].squeeze().cpu().numpy())**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squared_difftotal=(resdict['featuremaps'][2][:,:,:,:].squeeze().cpu().numpy()-resdict['recons'][2][:,:,:,:].squeeze().cpu().numpy())**2\n",
    "squared_diffhigh=(resdict['featuremaps'][2][:,:64,:,:].squeeze().cpu().numpy()-resdict['recons'][2][:,:64,:,:].squeeze().cpu().numpy())**2\n",
    "squared_diffmid=(resdict['featuremaps'][2][:,64:128,:,:].squeeze().cpu().numpy()-resdict['recons'][2][:,64:128,:,:].squeeze().cpu().numpy())**2\n",
    "squared_difflow=(resdict['featuremaps'][2][:,128:,:,:].squeeze().cpu().numpy()-resdict['recons'][2][:,128:,:,:].squeeze().cpu().numpy())**2\n",
    "\n",
    "squared_diffs = [squared_difftotal, squared_diffhigh, squared_diffmid, squared_difflow]\n",
    "titles = ['Total Squared Difference', 'High Squared Difference', 'Mid Squared Difference', 'Low Squared Difference']\n",
    "fig, axes = plt.subplots(1, len(squared_diffs) + 1, figsize=(20, 4))\n",
    "axes[0].imshow(Image.open(resdict['paths'][2]))\n",
    "axes[0].set_title('Original')\n",
    "axes[0].axis('off')\n",
    "for i, squared_diff in enumerate(squared_diffs):\n",
    "    axes[i+1].imshow(sum(squared_diff))\n",
    "    axes[i+1].set_title(titles[i])\n",
    "    axes[i+1].axis('off')\n",
    "plt.tight_layout(),plt.show()\n",
    "\n",
    "\n",
    "plot_images(resdict['featuremaps'][2][:,:64,:,:].squeeze().cpu().numpy())\n",
    "plot_images(resdict['recons'][2][:,:64,:,:].squeeze().cpu().numpy())\n",
    "plot_images((resdict['featuremaps'][2][:,:64,:,:].squeeze().cpu().numpy()-resdict['recons'][2][:,:64,:,:].squeeze().cpu().numpy())**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squared_diff=(resdict['featuremaps'][2][:,:,:,:].squeeze().cpu().numpy()-resdict['recons'][2][:,:,:,:].squeeze().cpu().numpy())**2\n",
    "\n",
    "\n",
    "\n",
    "plt.imshow(sum(squared_diff))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ultrad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
